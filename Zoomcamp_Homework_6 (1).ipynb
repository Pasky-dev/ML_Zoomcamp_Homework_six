{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IFeYOiTl7Obe"
      },
      "outputs": [],
      "source": [
        "# Download the data\n",
        "# !wget https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import the data\n",
        "import pandas as pd\n",
        "\n",
        "df  = pd.read_csv('jamb_exam_results.csv')\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDF1t8WX7bYI",
        "outputId": "b9e24329-8715-4135-8bbd-2defbd7ed958"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 17 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   jamb_score                    5000 non-null   int64  \n",
            " 1   study_hours_per_week          5000 non-null   int64  \n",
            " 2   attendance_rate               5000 non-null   int64  \n",
            " 3   teacher_quality               5000 non-null   int64  \n",
            " 4   distance_to_school            5000 non-null   float64\n",
            " 5   school_type                   5000 non-null   object \n",
            " 6   school_location               5000 non-null   object \n",
            " 7   extra_tutorials               5000 non-null   object \n",
            " 8   access_to_learning_materials  5000 non-null   object \n",
            " 9   parent_involvement            5000 non-null   object \n",
            " 10  it_knowledge                  5000 non-null   object \n",
            " 11  student_id                    5000 non-null   int64  \n",
            " 12  age                           5000 non-null   int64  \n",
            " 13  gender                        5000 non-null   object \n",
            " 14  socioeconomic_status          5000 non-null   object \n",
            " 15  parent_education_level        4109 non-null   object \n",
            " 16  assignments_completed         5000 non-null   int64  \n",
            "dtypes: float64(1), int64(7), object(9)\n",
            "memory usage: 664.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "df = df.drop('student_id', axis=1)\n",
        "df['parent_education_level'] = df['parent_education_level'].fillna(0)\n",
        "\n",
        "X = df.drop('jamb_score', axis=1)\n",
        "y = df.jamb_score"
      ],
      "metadata": {
        "id": "ZCe6Tgn98F4I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
        "\n",
        "# Step 3: Split the data\n",
        "train_full_df, test_df = train_test_split(df, test_size=0.2, random_state=1)\n",
        "train_df, val_df = train_test_split(train_full_df, test_size=0.25, random_state=1)\n",
        "\n",
        "# Separate the target (jamb_score) and features\n",
        "y_train = train_df['jamb_score'].values\n",
        "y_val = val_df['jamb_score'].values\n",
        "y_test = test_df['jamb_score'].values\n",
        "\n",
        "X_train = train_df.drop(columns=['jamb_score'])\n",
        "X_val = val_df.drop(columns=['jamb_score'])\n",
        "X_test = test_df.drop(columns=['jamb_score'])\n",
        "\n",
        "# Step 4: Convert data into a matrix format using DictVectorizer\n",
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "train_dict = X_train.to_dict(orient='records')\n",
        "val_dict = X_val.to_dict(orient='records')\n",
        "test_dict = X_test.to_dict(orient='records')\n",
        "\n",
        "x_train = dv.fit_transform(train_dict)\n",
        "x_val = dv.transform(val_dict)\n",
        "x_test = dv.transform(test_dict)"
      ],
      "metadata": {
        "id": "BD6_55opy0_T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 1\n",
        "Let's train a decision tree regressor to predict the jamb_score variable.\n",
        "\n",
        "Train a model with max_depth=1.\n",
        "Which feature is used for splitting the data?\n",
        "\n",
        "study_hours_per_week | attendance_rate | teacher_quality | distance_to_school\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=1)\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "# Identify which feature is used for splitting\n",
        "from sklearn.tree import export_text\n",
        "\n",
        "tree_rules = export_text(dt, feature_names=dv.get_feature_names_out())\n",
        "print(tree_rules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KCniTBJHBba",
        "outputId": "6c23b42b-b054-4e4a-e1a6-65512071897f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|--- study_hours_per_week <= 18.50\n",
            "|   |--- value: [155.24]\n",
            "|--- study_hours_per_week >  18.50\n",
            "|   |--- value: [188.59]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 2\n",
        "Train a random forest model with these parameters:\n",
        "n_estimators=10\n",
        "random_state=1\n",
        "n_jobs=-1 (optional - to make training faster)\n",
        "\n",
        "What's the RMSE of this model on validation?\n",
        "\n",
        "22.13  /  42.13  /  62.13  /  82.12\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(x_val)\n",
        "rmse = root_mean_squared_error(y_val, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drfPRNN4IimN",
        "outputId": "4052b1f5-72f6-4da7-d6f9-8cc02921d098"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 42.13724207871227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 3\n",
        "Now let's experiment with the n_estimators parameter\n",
        "\n",
        "Try different values of this parameter from 10 to 200 with step 10.\n",
        "Set random_state to 1.\n",
        "Evaluate the model on the validation dataset.\n",
        "After which value of n_estimators does RMSE stop improving? Consider 3 decimal places for calculating the answer.\n",
        "\n",
        "10  /  25  /  80  /  200\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "n_range = range(10, 201, 10)\n",
        "rmse_scores = []\n",
        "\n",
        "for n in n_range:\n",
        "    rf = RandomForestRegressor(n_estimators=n, random_state=1)\n",
        "    rf.fit(x_train, y_train)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred_val = rf.predict(x_val)\n",
        "\n",
        "    # Calculate RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "    rmse_scores.append((n, rmse))\n",
        "\n",
        "# Find after which value of n_estimators RMSE stops improving\n",
        "for n, rmse in rmse_scores:\n",
        "    print(f\"n_estimators={n} --> RMSE={rmse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2J-7Fh5IijR",
        "outputId": "2dde97b8-236d-4ed5-efac-af83a9cc55f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators=10 --> RMSE=42.137\n",
            "n_estimators=20 --> RMSE=41.461\n",
            "n_estimators=30 --> RMSE=41.106\n",
            "n_estimators=40 --> RMSE=40.917\n",
            "n_estimators=50 --> RMSE=40.852\n",
            "n_estimators=60 --> RMSE=40.784\n",
            "n_estimators=70 --> RMSE=40.677\n",
            "n_estimators=80 --> RMSE=40.539\n",
            "n_estimators=90 --> RMSE=40.504\n",
            "n_estimators=100 --> RMSE=40.517\n",
            "n_estimators=110 --> RMSE=40.593\n",
            "n_estimators=120 --> RMSE=40.625\n",
            "n_estimators=130 --> RMSE=40.651\n",
            "n_estimators=140 --> RMSE=40.595\n",
            "n_estimators=150 --> RMSE=40.597\n",
            "n_estimators=160 --> RMSE=40.604\n",
            "n_estimators=170 --> RMSE=40.628\n",
            "n_estimators=180 --> RMSE=40.641\n",
            "n_estimators=190 --> RMSE=40.631\n",
            "n_estimators=200 --> RMSE=40.601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 4\n",
        "Let's select the best max_depth:\n",
        "\n",
        "Try different values of max_depth: [10, 15, 20, 25]\n",
        "For each of these values,\n",
        "try different values of n_estimators from 10 till 200 (with step 10)\n",
        "calculate the mean RMSE\n",
        "Fix the random seed: random_state=1\n",
        "What's the best max_depth, using the mean RMSE?\n",
        "\n",
        "10  /  15  /  20  /  25\n",
        "\"\"\"\n",
        "\n",
        "all_scores = {}\n",
        "\n",
        "for depth in [10, 15, 20, 25]:\n",
        "    rmse = []\n",
        "\n",
        "    for i in range(10, 201, 10):\n",
        "        rf = RandomForestRegressor(n_estimators=i, max_depth=depth, random_state=1)\n",
        "        rf.fit(x_train, y_train)\n",
        "        y_pred = rf.predict(x_val)\n",
        "        rmse_score = root_mean_squared_error(y_val, y_pred)\n",
        "        rmse.append(rmse_score)\n",
        "\n",
        "    all_scores[depth] = rmse\n",
        "\n",
        "# After the loop, find the best max_depth with the lowest mean RMSE\n",
        "best_max_depth = min(all_scores, key=all_scores.get)\n",
        "best_rmse_scores = all_scores[best_max_depth]\n",
        "\n",
        "print(f\"Best max_depth: {best_max_depth}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqIiOEk5IiK7",
        "outputId": "2fa203c2-d21c-44ba-dfe8-4ea89ecada0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Best max_depth: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 5\n",
        "We can extract feature importance information from tree-based models.\n",
        "In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
        "For this homework question, we'll find the most important feature:\n",
        "\n",
        "Train the model with these parameters:\n",
        "n_estimators=10,\n",
        "max_depth=20,\n",
        "random_state=1,\n",
        "n_jobs=-1 (optional)\n",
        "Get the feature importance information from this model\n",
        "What's the most important feature (among these 4)?\n",
        "\n",
        "study_hours_per_week / attendance_rate  /  distance_to_school /  teacher_quality\n",
        "\"\"\"\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
        "rf.fit(x_train, y_train)\n",
        "importances = rf.feature_importances_    # Get the feature importances\n",
        "\n",
        "feature_names = X.columns     # Get feature names (assuming your feature names are stored in X_train.columns)\n",
        "\n",
        "feature_importance_list = sorted(zip(feature_names, importances), reverse=True)\n",
        "for feature, importance in feature_importance_list:\n",
        "    print(f\"{feature} --> {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbDHv5CPJ-7g",
        "outputId": "c04d6ebe-d87c-42a3-9e74-224966a7f3ea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_quality --> 0.0693\n",
            "study_hours_per_week --> 0.0123\n",
            "socioeconomic_status --> 0.0091\n",
            "school_type --> 0.1497\n",
            "school_location --> 0.1365\n",
            "parent_involvement --> 0.0093\n",
            "parent_education_level --> 0.0000\n",
            "it_knowledge --> 0.0104\n",
            "gender --> 0.0124\n",
            "extra_tutorials --> 0.0135\n",
            "distance_to_school --> 0.0315\n",
            "attendance_rate --> 0.0103\n",
            "assignments_completed --> 0.0155\n",
            "age --> 0.0177\n",
            "access_to_learning_materials --> 0.0091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Question 6\n",
        "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
        "Install XGBoost\n",
        "Create DMatrix for train and validation\n",
        "Create a watchlist\n",
        "Train a model with these parameters for 100 rounds:\n",
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.3, 'max_depth': 6,  'min_child_weight': 1,'objective': 'reg:squarederror',\n",
        "    'nthread': 8,  'seed': 1, 'verbosity': 1 }\n",
        "\"\"\"\n",
        "\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "qsqDsSP5pkhX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(x_train, label=y_train, feature_names=dv.feature_names_)\n",
        "dval = xgb.DMatrix(x_val, label=y_val, feature_names=dv.feature_names_)\n",
        "\n",
        "# Create the watchlist for monitoring\n",
        "watchlist = [(dtrain, 'train'), (dval, 'eval')]"
      ],
      "metadata": {
        "id": "_4rO8LYmpUMu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    'eta': 0.3, 'max_depth': 6,\n",
        "    'min_child_weight': 1,\n",
        "    'objective': 'reg:squarederror',\n",
        "    'nthread': 8,'seed': 1,'verbosity': 1\n",
        "}\n",
        "\n",
        "model = xgb.train(xgb_params, dtrain, num_boost_round=100,evals=watchlist, verbose_eval=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LoLhFAynAqS",
        "outputId": "5de0b4bd-9079-4aec-975b-cbb97271752b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-rmse:42.69552\teval-rmse:44.86028\n",
            "[10]\ttrain-rmse:31.55119\teval-rmse:40.83684\n",
            "[20]\ttrain-rmse:27.24424\teval-rmse:41.80313\n",
            "[30]\ttrain-rmse:24.12906\teval-rmse:42.28557\n",
            "[40]\ttrain-rmse:21.45994\teval-rmse:42.77917\n",
            "[50]\ttrain-rmse:19.30407\teval-rmse:43.11630\n",
            "[60]\ttrain-rmse:17.42414\teval-rmse:43.40830\n",
            "[70]\ttrain-rmse:15.74173\teval-rmse:43.77894\n",
            "[80]\ttrain-rmse:14.28350\teval-rmse:44.08528\n",
            "[90]\ttrain-rmse:12.90222\teval-rmse:44.30365\n",
            "[99]\ttrain-rmse:11.56417\teval-rmse:44.43210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    'eta': 0.1, 'max_depth': 6,\n",
        "    'min_child_weight': 1,\n",
        "    'objective': 'reg:squarederror',\n",
        "    'nthread': 8,'seed': 1,'verbosity': 1\n",
        "}\n",
        "\n",
        "model = xgb.train(xgb_params, dtrain, num_boost_round=100,evals=watchlist, verbose_eval=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBv31NovtPr4",
        "outputId": "71614d87-9303-4d95-d0e8-9a422c94b490"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-rmse:45.50072\teval-rmse:46.99373\n",
            "[10]\ttrain-rmse:37.11353\teval-rmse:41.55631\n",
            "[20]\ttrain-rmse:33.57997\teval-rmse:40.37859\n",
            "[30]\ttrain-rmse:31.47315\teval-rmse:40.20963\n",
            "[40]\ttrain-rmse:29.89807\teval-rmse:40.15747\n",
            "[50]\ttrain-rmse:28.58793\teval-rmse:40.28533\n",
            "[60]\ttrain-rmse:27.26360\teval-rmse:40.55054\n",
            "[70]\ttrain-rmse:26.05959\teval-rmse:40.73555\n",
            "[80]\ttrain-rmse:25.13835\teval-rmse:40.82813\n",
            "[90]\ttrain-rmse:23.93958\teval-rmse:40.89645\n",
            "[99]\ttrain-rmse:23.14487\teval-rmse:41.04335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGjhPGgsuC6l"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}